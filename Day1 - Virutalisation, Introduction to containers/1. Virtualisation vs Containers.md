
# Physical servers

We have physical servers, and in on premise, we have 1000s of physical resources, and not all of them are being completely utilised (cpu, ram are left unutilised)

# Hypervisors

Hypervisor were introduces to solve the above problem and it uses a concept called virtualisation. Virtualisation is used to create a lot of virtual machines on top of our physical server. 

VM is a logical isoloation, unlike physical server which we can see, and for each VM, we have OS for each VM. On top of this VM, we would run our applications.


Now since each of the application have their own OS, they are secure and logically tightly separated running on same physical server. 

@ Note - App A hosted on VM A cannot use kernel resources of App B hosted on VM B

# Why then need to move to containers?

So suppose, i had a physical server, my laptop for instance, having 100 GB ram and 100 cpu, i installed hypervisor on top of it, and created 4 VM for 4 diff teams. On top of which, we installed O.S, same process as creating EC2 ON AWS

Now you reliase that all of the VMs are not utilizing the resources to their fullest capacity. app1 receives max traffic, and still utilised only 10 GB, wasting the rest 15 gb. 

suppose a team making use of 1000 ec2, and this resource utilization is not done properly, could result in resources under utilised and adding cost. To solve this containers came in place


# Containers

Containers solved the problem in a way that we can create mulitple containers on the same VM, and they are lightweight in nature, and when containers are not running they dont use resources from kernel. 

@ Note - when they are not running They allow other containers to use the resources from kernel or host O.S. Hence we can run n no of continaers depending on how much your containers are using the O.S

For logical isolation btw multiple containers, there are system dependencies which perform this logical isolation.

/bin, /sbin, /etc, /lib, /usr, /var, /root --> These files and folders are part of our containers image,  and are not shared with kernel 

Container can be created in 2 way -

1. On top of physical server as well
2. On top of VM - creating containers on EC2


Just like to create VM, we need a hypervisor, or virtualisation platform. So similar, for creating container, we would need a containerisation platform, and on top of that we create containers.

The Model 2 one is mostly used, as maintaining physical servers require a lot of resources. AWS or any other cloud platform takes care of physical server, so maintenace you dont have to do.

# Advantage of creating containers

1. Containers are lightweight in nature - **Why** 

Docker container do not have a complete O.S. like VM. Containers use the resources from base O.S or from the VM they are running on. For eg, if ec2 has a linux O.S, then the docker container, if requires some linux resources, will share resources from host  O.S. 

# Container definition

Containers have a minimal OS/Base image. So a container is package which is combination of your application libraries + dependency + system dependency

All other system realted packages, for eg etc, will be used from host O.S

2. They are easy to ship.

# Lifecycle of container


There are three important things,
First you create a Dockerfile

    docker build -> builds docker images from Dockerfile
    docker run -> runs container from docker images
    docker push -> push the container image to public/private regestries to share the docker images.


This steps are performed with help of docker commands, which docker cli interact with docker engine to create the image and container.

# Problem with docker 

1. Since docker engine is the main component at work here, it also becomes single point of failure. If docker engine goes down, docker containers will stop working.
docker daemon is a single process, i.e monolithic. So if it goes down, all the containers are affected.

2. Also , when a docker image is created, multiple layers are created which can consume lot of space in your disk. 

To solve this layer problem along with SPOF, BUILDA came up

3. by default, docker has to be installed using root user only. and docker daemon executes everything using root user only. 

We need to add our user to docker group - for eg, if ubuntu is your user, you can do it like - 

    sudo usermod -aG docker ubuntu

# Drawback

1. To create a backup of your VM, we will create a snapshot. With container, the snapshot would be 100-200 mb only.

2. VM have a full OS, so they are completely isolated, whereas containers do not have a complete OS. The logical isolation complete is not there.

3. Resource Utilization: Containers share the host operating system kernel, making them lighter and faster than VMs. VMs have a full-fledged OS and hypervisor, making them more resource-intensive.

4. Portability: Containers are designed to be portable and can run on any system with a compatible host operating system. VMs are less portable as they need a compatible hypervisor to run.

5. Security: VMs provide a higher level of security as each VM has its own operating system and can be isolated from the host and other VMs. Containers provide less isolation, as they share the host operating system.